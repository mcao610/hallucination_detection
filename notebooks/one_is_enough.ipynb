{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from fairseq.models.bart import BARTModel\n",
    "from utils import read_lines\n",
    "\n",
    "from transformers import BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = json.load(open('path_config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-21bc8af87b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m posterior_bart = BARTModel.from_pretrained(PATH['bart.large.xsum'],\n\u001b[1;32m      2\u001b[0m                                            \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                            data_name_or_path=PATH['bart.large.xsum'])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# posterior_bart = BARTModel.from_pretrained(PATH['xsum_cmlm_bos'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/models/bart/model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name_or_path, checkpoint_file, data_name_or_path, bpe, sample_break_mode, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mload_checkpoint_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0msample_break_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_break_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         )\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBARTHubInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/hub_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name_or_path, checkpoint_file, data_name_or_path, archive_map, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     models, args, task = checkpoint_utils.load_model_ensemble_and_task(\n\u001b[1;32m     72\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathsep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0marg_overrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     )\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/checkpoint_utils.py\u001b[0m in \u001b[0;36mload_model_ensemble_and_task\u001b[0;34m(filenames, arg_overrides, task, strict, suffix, num_shards, state)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# build model for ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/tasks/__init__.py\u001b[0m in \u001b[0;36msetup_task\u001b[0;34m(cfg, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Could not infer task type from {cfg}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/tasks/translation.py\u001b[0m in \u001b[0;36msetup_task\u001b[0;34m(cls, args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m         )\n\u001b[1;32m    271\u001b[0m         tgt_dict = cls.load_dictionary(\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dict.{}.txt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         )\n\u001b[1;32m    274\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msrc_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtgt_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/tasks/fairseq_task.py\u001b[0m in \u001b[0;36mload_dictionary\u001b[0;34m(cls, filename)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/data/dictionary.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, f)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[1;32m    214\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/data/dictionary.py\u001b[0m in \u001b[0;36madd_from_file\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfnfe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mfnfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/data/dictionary.py\u001b[0m in \u001b[0;36madd_from_file\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mindices_start_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env37/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "posterior_bart = BARTModel.from_pretrained(PATH['bart.large.xsum'],\n",
    "                                           checkpoint_file='model.pt',\n",
    "                                           data_name_or_path=PATH['bart.large.xsum'])\n",
    "\n",
    "# posterior_bart = BARTModel.from_pretrained(PATH['xsum_cmlm_bos'],\n",
    "#                                            checkpoint_file='checkpoint_best.pt',\n",
    "#                                            data_name_or_path=PATH['data_name_or_path'])\n",
    "\n",
    "# posterior_bart = BARTModel.from_pretrained(PATH['xsum_cmlm_scratch_cedar_warmup_10000'],\n",
    "#                                            checkpoint_file='checkpoint_best.pt',\n",
    "#                                            data_name_or_path=PATH['data_name_or_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior_bart = BARTModel.from_pretrained(PATH['bart.large'],\n",
    "#                                        checkpoint_file='model.pt',\n",
    "#                                        data_name_or_path=PATH['bart.large'])\n",
    "\n",
    "# prior_bart = BARTModel.from_pretrained(PATH['cnndm_cmlm_cedar'],\n",
    "#                                        checkpoint_file='checkpoint_best.pt',\n",
    "#                                        data_name_or_path=PATH['data_name_or_path'])\n",
    "\n",
    "prior_bart = BARTModel.from_pretrained(PATH['cnndm_cmlm_scratch_cedar_warmup_20000'],\n",
    "                                       checkpoint_file='checkpoint_best.pt',\n",
    "                                       data_name_or_path=PATH['data_name_or_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = PATH['xsum_fariseq'] + '/test.source'\n",
    "target_path = PATH['xsum_fariseq'] + '/test.target'\n",
    "xsum_source = read_lines(document_path)\n",
    "xsum_target = read_lines(target_path)\n",
    "print(len(xsum_source))\n",
    "assert len(xsum_source) == len(xsum_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.data.data_utils import collate_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalSequenceGenerator:\n",
    "    \"\"\"Conditional sequence generator for calculating prior and posterior probability.\"\"\"\n",
    "    def __init__(self, bart):\n",
    "        self.bart = bart\n",
    "        self.tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "        \n",
    "        self.encode_func = bart.encode\n",
    "        self.decode_func = bart.decode\n",
    "        self.max_positions = bart.max_positions\n",
    "        self.encode_line = bart.task.source_dictionary.encode_line\n",
    "        \n",
    "        self._initialize()\n",
    "    \n",
    "    def _initialize(self):\n",
    "        \"\"\"Set BART model to evaluation mode.\"\"\"\n",
    "        self.bart.cuda()\n",
    "        self.bart.eval()\n",
    "        self.bart.half()\n",
    "        \n",
    "    def tokenize(self, input_str, append_bos=False, append_eos=True, left_pad=True):\n",
    "        \"\"\"BPE-encode a sentence (or multiple sentences).\n",
    "\n",
    "        Args:\n",
    "            input_str (str or List[str]): input sentence to be tokenized.\n",
    "            append_bos (bool): self-explained.\n",
    "            append_eos (bool): self-explained.\n",
    "\n",
    "        Return:\n",
    "            input_ids (torch.Tensor): [batch_size, length]\n",
    "            src_lengths (torch.Tensor): [batch_size]\n",
    "        \"\"\"\n",
    "        if type(input_str) == type(''):\n",
    "            input_str = [input_str]\n",
    "\n",
    "        input_ids = []\n",
    "        for ins in input_str:\n",
    "            tokens = self.bart.bpe.encode(ins)  # <mask>: 1279 27932 29\n",
    "            calibration = sum([append_bos, append_eos])\n",
    "            if len(tokens.split(\" \")) > min(self.max_positions) - calibration:\n",
    "                tokens = \" \".join(tokens.split(\" \")[: min(self.max_positions) - calibration])\n",
    "\n",
    "            tokens = \"<s> \" + tokens if append_bos else tokens\n",
    "            tokens = tokens + \" </s>\" if append_eos else tokens\n",
    "            ids = self.encode_line(tokens, append_eos=False).long()\n",
    "            input_ids.append(ids)\n",
    "\n",
    "        input_ids = collate_tokens(input_ids, pad_idx=1, left_pad=left_pad).cuda()\n",
    "        input_lengths = torch.sum(input_ids != 1, dim=1).cuda()\n",
    "\n",
    "        return input_ids, input_lengths\n",
    "    \n",
    "    def tokenize_with_mask(self, input_str):\n",
    "        \"\"\"Tokenize sentence with a special <mask> token in it.\n",
    "\n",
    "        Args:\n",
    "            input_str (str or List[str]): input sentence to be tokenized.\n",
    "\n",
    "        Return:\n",
    "            input_ids (torch.Tensor): [batch_size, length]\n",
    "            src_lengths (torch.Tensor): [batch_size]\n",
    "        \"\"\"\n",
    "        input_ids = self.tokenizer(input_str, return_tensors='pt', padding=True)['input_ids'].cuda()\n",
    "        input_lengths = torch.sum(input_ids != 1, dim=1).cuda()\n",
    "        return input_ids, input_lengths\n",
    "    \n",
    "    def generate(self, src_input, tgt_input=None):\n",
    "        \"\"\"Conditional generation.\n",
    "        \n",
    "        Args:\n",
    "            src_input (str or List[str]): input source sentence to be tokenized.\n",
    "            tgt_input (str or List[str]): input target sentence to be tokenized.\n",
    "        \"\"\"\n",
    "        input_ids, lengths = self.tokenize(src_input, append_bos=False) \n",
    "        \n",
    "        target_ids = None\n",
    "        if tgt_input is not None:\n",
    "            assert len(src_input) == len(tgt_input), \"source & target length should match.\"\n",
    "            target_ids, _ = self.tokenize(tgt_input, append_bos=False, left_pad=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            encoder_output = self.encode_sequence(input_ids, lengths)\n",
    "            decoder_output = self.decode_sequence(encoder_output, \n",
    "                                                  target_ids=target_ids,\n",
    "                                                  prefix_tokens=[2])\n",
    "        return decoder_output\n",
    "    \n",
    "    def mask_filling(self, src_input, tgt_input=None):\n",
    "        \"\"\"\n",
    "        Filling the mask in sentence(s).\n",
    "        \"\"\"\n",
    "        input_ids, lengths = self.tokenize_with_mask(src_input)\n",
    "        \n",
    "        target_ids = None\n",
    "        if tgt_input is not None:\n",
    "            assert len(src_input) == len(tgt_input), \"source & target length should match.\"\n",
    "            target_ids, _ = self.tokenize(tgt_input, left_pad=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_output = self.encode_sequence(input_ids, lengths)\n",
    "            decoder_output = self.decode_sequence(encoder_output, \n",
    "                                                  target_ids=target_ids,\n",
    "                                                  prefix_tokens=[2, 0])\n",
    "        return decoder_output\n",
    "    \n",
    "    def encode_sequence(self, input_ids, lengths):\n",
    "        return self.bart.model.encoder(input_ids, src_lengths=lengths)\n",
    "        \n",
    "    def decode_sequence(\n",
    "        self,\n",
    "        encoder_out,\n",
    "        target_ids=None,\n",
    "        min_decode_step=3,\n",
    "        max_decode_step=100,\n",
    "        pad_id=1,\n",
    "        eos_id=2,\n",
    "        prefix_tokens=[2, 0],\n",
    "    ):\n",
    "        batch_size = encoder_out['encoder_padding_mask'][0].shape[0]\n",
    "        init_input = torch.tensor([prefix_tokens] * batch_size, dtype=torch.long).cuda()\n",
    "        token_probs, tokens = None, [[] for i in range(batch_size)]\n",
    "        end_mask = torch.tensor([False] * batch_size).cuda()\n",
    "\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        for step in range(max_decode_step):\n",
    "            decoder_outputs = self.bart.model.decoder(init_input, encoder_out, features_only=False)\n",
    "            logits = decoder_outputs[0][:, -1, :]  # logits: [batch_size, vocab]\n",
    "            attn = decoder_outputs[1]['attn'][0]  # [batch_size, prev_token_len, src_token_len]\n",
    "\n",
    "            if step + 1 < min_decode_step:\n",
    "                logits[:, eos_id] = -math.inf  # mask <EOS> token when within minimal step\n",
    "            logits[:, pad_id], logits[:, 0] = -math.inf, -math.inf  # never select <PAD> & <BOS> token\n",
    "            probs = softmax(logits)  # probs: [batch_size, vocab]\n",
    "\n",
    "            # select tokens\n",
    "            if target_ids is not None:\n",
    "                selected_token = target_ids[:, step]\n",
    "            else:\n",
    "                value, indices = torch.topk(probs, 5, dim=1)\n",
    "                selected_token = indices[:, 0]\n",
    "\n",
    "            selected_token = selected_token.masked_fill(end_mask, pad_id)\n",
    "            init_input = torch.cat([init_input, selected_token.unsqueeze(1)], dim=-1)\n",
    "            \n",
    "            probs = torch.gather(probs, 1, selected_token.unsqueeze(1)).detach()\n",
    "            probs = probs.masked_fill(end_mask.unsqueeze(1), 1.0)\n",
    "            \n",
    "            # str & probability\n",
    "            token_probs = probs if token_probs is None else torch.cat([token_probs, probs], dim=-1)\n",
    "            for t, s in zip(tokens, selected_token):\n",
    "                t.append(self.decode_func(s.unsqueeze(0)) if s.item() != pad_id else '<pad>')\n",
    "            \n",
    "            # stop generation when all finished\n",
    "            end_mask = torch.logical_or(end_mask, selected_token == eos_id) \n",
    "            if end_mask.sum().item() == batch_size:\n",
    "                break\n",
    "\n",
    "        return init_input, tokens, token_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability(position, tokens, probs, entity):\n",
    "    \"\"\"Calculate the probability of a span.\n",
    "\n",
    "    Args:\n",
    "        position: (start, end)\n",
    "        tokens: ['The', ' Archbishop', ' of', ...]\n",
    "        probs: [0.50, 0.49, 0.88, ...]\n",
    "        entity: Rodgers\n",
    "    \"\"\"\n",
    "    assert len(tokens) == len(probs), \"Tokens and token probabilities does not match.\"\n",
    "    \n",
    "    end_pointer, end_pos = 0, []\n",
    "    for t in tokens:\n",
    "        end_pointer += len(t)\n",
    "        end_pos.append(end_pointer)\n",
    "    \n",
    "    assert position[1] in end_pos, \"- {}\\n- {}\\n- {}\\n- {}\\n- {}\\n\".format(position, tokens, probs, entity, end_pos)\n",
    "    last_index = end_pos.index(position[1])\n",
    "    indexes = [last_index]\n",
    "    total_length = len(tokens[last_index])\n",
    "    \n",
    "    while total_length < (position[1] - position[0]):\n",
    "        last_index -= 1\n",
    "        assert last_index >= 0\n",
    "        indexes.append(last_index)\n",
    "        total_length += len(tokens[last_index])\n",
    "    \n",
    "    indexes.reverse()\n",
    "    \n",
    "    generated = ''.join([tokens[i] for i in indexes])\n",
    "    assert entity in generated, 'entity: {}; span: {}'.format(entity, generated)\n",
    "    \n",
    "    prob = 1.0\n",
    "    for i in indexes:\n",
    "        prob *= probs[i]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmlm_probability(generator, src_input, tgt_input, position, entity):\n",
    "    outputs = generator.generate(src_input, tgt_input=tgt_input)\n",
    "    init_input, tokens, token_probs = outputs\n",
    "    \n",
    "    probs = []\n",
    "    for p, tok, tokp, e in zip(position, tokens, token_probs, entity):\n",
    "        probs.append(get_probability(p, tok, tokp, e).item())\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior_probability(generator, src_input, tgt_input, position, entity):\n",
    "    \"\"\"Tokenize input with a special <mask> token.\"\"\"\n",
    "    assert len(src_input) == len(tgt_input), \"source & target length should match.\"\n",
    "    decoder_output = generator.mask_filling(src_input, tgt_input)\n",
    "    init_input, tokens, token_probs = decoder_output\n",
    "    \n",
    "    probs = []\n",
    "    for p, tok, tokp, e in zip(position, tokens, token_probs, entity):\n",
    "        probs.append(get_probability(p, tok, tokp, e).item())\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test One Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_clm_inputs(source, target, ent_parts=None):\n",
    "    \"\"\"For Conditional Language Model. For XSum BART only.\"\"\"\n",
    "    if ent_parts is None:\n",
    "        ent_parts = nlp(target).to_json()['ents']\n",
    "    \n",
    "    entities, positions = [], []\n",
    "    inputs, targets = [], []\n",
    "\n",
    "    for e in ent_parts:\n",
    "        inputs.append(source)\n",
    "        targets.append(target)\n",
    "        positions.append((e['start'], e['end']))\n",
    "        entities.append(target[e['start']: e['end']])\n",
    "\n",
    "    return inputs, targets, positions, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mlm_inputs(source, target, ent_parts=None):\n",
    "    \"\"\"For Masked Language Model. For BART only.\"\"\"\n",
    "    if ent_parts is None:\n",
    "        ent_parts = nlp(target).to_json()['ents']\n",
    "    \n",
    "    inputs, targets = [], []\n",
    "    positions, entities = [], []\n",
    "\n",
    "    for e in ent_parts:\n",
    "        inputs.append(target[0: e['start']] + '<mask>' + target[e['end']:])\n",
    "        targets.append(target)\n",
    "        entities.append(target[e['start']: e['end']])\n",
    "        positions.append((e['start'], e['end']))\n",
    "    \n",
    "    return inputs, targets, positions, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cmlm_inputs(source, target, ent_parts=None):\n",
    "    \"\"\"For Masked Language Model.\"\"\"\n",
    "    if ent_parts is None:\n",
    "        ent_parts = nlp(target).to_json()['ents']\n",
    "    \n",
    "    inputs, targets = [], []\n",
    "    positions, entities = [], []\n",
    "\n",
    "    for e in ent_parts:\n",
    "        masked_hypothesis = target[0: e['start']] + '###' + target[e['end']:]\n",
    "        masked_hypothesis = '<s> ' + masked_hypothesis + ' <\\s> ' + source\n",
    "        inputs.append(masked_hypothesis)\n",
    "        targets.append('<s> ' + target)\n",
    "        \n",
    "        entities.append(target[e['start']: e['end']])\n",
    "        positions.append((e['start'] + 4, e['end'] + 4))\n",
    "\n",
    "    return inputs, targets, positions, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 9444\n",
    "\n",
    "source = xsum_source[INDEX]\n",
    "target = 'Twin-to-twin transfusion syndrome (TTTS) is being tracked by a hospital in Cardiff in a bid to save the lives of babies born with the condition.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_parts = [{'start': 35, 'end': 39, 'label': 0, 'type': 'ORG', 'ent': 'TTTS'},\n",
    "             {'start': 75, 'end': 82, 'label': 2, 'type': 'LOC', 'ent': 'Cardiff'}]\n",
    "\n",
    "for e in ent_parts:\n",
    "    print('{} - {}'.format(e, target[e['start']: e['end']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_model = ConditionalSequenceGenerator(prior_bart)\n",
    "posterior_model = ConditionalSequenceGenerator(posterior_bart)\n",
    "\n",
    "pri_args = prepare_cmlm_inputs(source, target, ent_parts)\n",
    "pos_args = prepare_clm_inputs(source, target, ent_parts)\n",
    "\n",
    "prior_probs = get_cmlm_probability(prior_model, pri_args[0], pri_args[1], pri_args[2], pri_args[3])\n",
    "posterior_probs = get_cmlm_probability(posterior_model, pos_args[0], pos_args[1], pos_args[2], pos_args[3])\n",
    "\n",
    "assert len(prior_probs) == len(posterior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- prior: {}'.format(prior_probs))\n",
    "print('- posterior: {}'.format(posterior_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Annotated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('annotated.json', 'r'))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for INDEX in tqdm(range(len(data))):\n",
    "    source = xsum_source[data[INDEX]['id']]\n",
    "    target = data[INDEX]['pred']\n",
    "    \n",
    "    pri_args = prepare_cmlm_inputs(source, target, data[INDEX]['ents'])\n",
    "    pos_args = prepare_clm_inputs(source, target, data[INDEX]['ents'])\n",
    "\n",
    "    prior_probs = get_cmlm_probability(prior_model, pri_args[0], pri_args[1], pri_args[2], pri_args[3])\n",
    "    posterior_probs = get_cmlm_probability(posterior_model, pos_args[0], pos_args[1], pos_args[2], pos_args[3])\n",
    "    \n",
    "    assert len(prior_probs) == len(posterior_probs) == len(data[INDEX]['ents']), \"{};\\n {};\\n {}\".format(prior_probs, posterior_probs, data[INDEX]['ents'])\n",
    "    for i in range(len(prior_probs)):\n",
    "        data[INDEX]['ents'][i]['prior'] = prior_probs[i]\n",
    "        data[INDEX]['ents'][i]['posterior'] = posterior_probs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('annotated_with_probability.json', 'w') as fout:\n",
    "#     json.dump(data , fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior/Posterior Distribution Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_posterior = []\n",
    "for d in data:\n",
    "    for e in d['ents']:\n",
    "        e['id'] = d['id']\n",
    "        prior_posterior.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9.0, 7.0))\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green']\n",
    "\n",
    "no_hallucinated = [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 0]\n",
    "hallucinated_true = [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 1]\n",
    "hallucinated_false = [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 2]\n",
    "hallucinated_intrinsic = [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 3]\n",
    "\n",
    "ax.scatter([i[0] for i in no_hallucinated], \n",
    "           [i[1] for i in no_hallucinated], c='tab:blue', s=[i[1]*100 + 40 for i in no_hallucinated], label='Non-hallucination', alpha=0.7)\n",
    "\n",
    "ax.scatter([i[0] for i in hallucinated_true], \n",
    "           [i[1] for i in hallucinated_true], c='tab:green', s=[i[1]*100 + 40 for i in hallucinated_true], label='Hallucination True', alpha=0.65)\n",
    "\n",
    "ax.scatter([i[0] for i in hallucinated_false], \n",
    "           [i[1] for i in hallucinated_false], c='tab:orange', s=[i[1]*100 + 40 for i in hallucinated_false], label='Hallucination False', alpha=0.6)\n",
    "\n",
    "ax.scatter([i[0] for i in hallucinated_intrinsic], \n",
    "           [i[1] for i in hallucinated_intrinsic], c='tab:red', s=[i[1]*100 + 40 for i in hallucinated_intrinsic], label='Intrinsic Hallucination', alpha=0.6)\n",
    "\n",
    "ax.scatter([1.0], [1.0], c='tab:gray', s=10)\n",
    "\n",
    "ax.set_xlabel('Prior Probability')\n",
    "ax.set_ylabel('Posterior Probability')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.savefig('foo.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in prior_posterior:\n",
    "#     if p['prior'] > 0.9:\n",
    "#         print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_posterior[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label, factual_label, hallucination_label = [], [], []\n",
    "prior_probabilities, posterior_probabilities = [], []\n",
    "\n",
    "for p in prior_posterior:\n",
    "    if p['label'] is not None and p['label'] != 3:\n",
    "        if p['label'] == 0 or p['label'] == 1:\n",
    "            factual_label.append(1)\n",
    "        elif p['label'] == 2:\n",
    "            factual_label.append(0)\n",
    "        else:\n",
    "            raise Exception(\"ERROR! {}\".format(p['label']))\n",
    "            \n",
    "        if p['label'] == 0:\n",
    "            hallucination_label.append(0)\n",
    "        elif p['label'] == 2 or p['label'] == 1:\n",
    "            hallucination_label.append(1)\n",
    "        else:\n",
    "            raise Exception(\"ERROR! {}\".format(p['label']))\n",
    "            \n",
    "        true_label.append(p['label'])\n",
    "        prior_probabilities.append(p['prior'])\n",
    "        posterior_probabilities.append(p['posterior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_baseline_preds = []\n",
    "overlap_preds = []\n",
    "\n",
    "for p in prior_posterior:\n",
    "    if p['label'] is not None and p['label'] != 3:\n",
    "        source = xsum_source[p['id']]\n",
    "\n",
    "        if p['ent'].lower() in source.lower():\n",
    "            overlap_preds.append(1)\n",
    "        else:\n",
    "            overlap_preds.append(0)\n",
    "\n",
    "        if p['posterior'] > p['prior']:\n",
    "            lm_baseline_preds.append(1)\n",
    "        else:\n",
    "            lm_baseline_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(factual_label, overlap_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], overlap_preds, \n",
    "                            target_names=['Non-hallucinated', 'Hallucinated'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(factual_label, lm_baseline_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], lm_baseline_preds, \n",
    "                            target_names=['Non-hallucinated', 'Hallucinated'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import neighbors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_error(prior_probs, posterior_probs, labels, n_neighbors=15):\n",
    "    assert len(prior_probs) == len(posterior_probs) == len(labels)\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(len(prior_probs)):\n",
    "        train_features, train_labels = [], []\n",
    "        for j in range(len(prior_probs)):\n",
    "            if j != i:\n",
    "                train_features.append([prior_probs[j], posterior_probs[j]])\n",
    "                train_labels.append(labels[j])\n",
    "    \n",
    "        classifier = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='auto')\n",
    "\n",
    "        x_mat = np.array(train_features)\n",
    "        y_vec = np.array(train_labels)\n",
    "        classifier.fit(x_mat, y_vec)\n",
    "        \n",
    "        test_features = np.array([[prior_probs[i], posterior_probs[i]]])\n",
    "        Z = classifier.predict(test_features)\n",
    "        preds.append(Z[0])\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_label_reverse = [1 if i == 0 else 0 for i in hallucination_label]\n",
    "knn_preds = leave_one_out_error(prior_probabilities, posterior_probabilities, hallucination_label_reverse, n_neighbors=12)\n",
    "print(classification_report(hallucination_label_reverse, knn_preds, target_names=['Hallucinated', 'Non-hallucinated'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_preds = leave_one_out_error(prior_probabilities, posterior_probabilities, factual_label, n_neighbors=10)\n",
    "print(classification_report(factual_label, knn_preds, target_names=['Non-Factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(taskname, HJ, model_probs, labels, n_neighbors=15, fig_size=(4.5, 3.5), \n",
    "         colors=['red', 'blue'], legend_labels=['Factual', 'Non-factual']):\n",
    "    classifier = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='auto')\n",
    "\n",
    "    larray = np.array(labels)\n",
    "    HJ = np.array(HJ)\n",
    "    nmodel_probs = np.array(model_probs)\n",
    "    \n",
    "    pin = nmodel_probs\n",
    "    x_mat = np.vstack([pin / np.std(pin), HJ / np.std(HJ)]).transpose()\n",
    "    y_vec = np.array(labels)\n",
    "    \n",
    "    classifier.fit(x_mat,y_vec)\n",
    "    \n",
    "    # Plot the decision boundary. For that, we will asign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    x_min, x_max = x_mat[:, 0].min() - .5, x_mat[:, 0].max() + .5\n",
    "    y_min, y_max = x_mat[:, 1].min() - .5, x_mat[:, 1].max() + .5\n",
    "    \n",
    "    h = 0.05\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = classifier.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    xx_1, yy_1 = np.meshgrid(np.arange(x_min, x_max, h) * np.std(pin),\n",
    "                             np.arange(y_min, y_max, h) * np.std(HJ))\n",
    "    \n",
    "    # Plot color map\n",
    "    cm = plt.cm.RdBu\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "    ax.contourf(xx_1, yy_1, Z, cmap=cm, alpha=.7)\n",
    "    \n",
    "    ax.scatter(np.array(pin)[np.nonzero(larray==1)[0]], np.array(HJ)[np.nonzero(larray==1)[0]], \n",
    "               color=colors[1], edgecolor='black', label=legend_labels[1], alpha=0.8)\n",
    "    ax.scatter(np.array(pin)[np.nonzero(larray==0)[0]], np.array(HJ)[np.nonzero(larray==0)[0]], \n",
    "               color=colors[0], edgecolor='black', label=legend_labels[0], marker='s', alpha=0.8)\n",
    "\n",
    "    \n",
    "    # Plot Hist diagram\n",
    "    divider = make_axes_locatable(ax)\n",
    "    axHistx = divider.append_axes(\"top\", 0.7, pad=0.0, sharex=ax)\n",
    "    axHisty = divider.append_axes(\"right\", 0.7, pad=0.0, sharey=ax)\n",
    "    axHistx.xaxis.set_tick_params(labelbottom=False, bottom=False)\n",
    "    axHistx.yaxis.set_tick_params(labelleft=False, left=False)\n",
    "    axHisty.xaxis.set_tick_params(labelbottom=False, bottom=False)\n",
    "    axHisty.yaxis.set_tick_params(labelleft=False, left=False)\n",
    "    b_subset = np.nonzero(larray==1)[0]\n",
    "    r_subset = np.nonzero(larray==0)[0]\n",
    "    x = np.array(pin)\n",
    "    y = np.array(HJ)\n",
    "    _ = axHistx.hist(x[b_subset], color=colors[1], bins=np.arange(x_min, x_max, 0.3)*np.std(pin), alpha=0.7)\n",
    "    _ = axHistx.hist(x[r_subset], color=colors[0], bins=np.arange(x_min, x_max, 0.3)*np.std(pin), alpha=0.7)\n",
    "    _ = axHisty.hist(y[b_subset], color=colors[1], bins=np.arange(y_min, y_max, 0.3)*np.std(HJ), orientation='horizontal', alpha=0.7)\n",
    "    _ = axHisty.hist(y[r_subset], color=colors[0], bins=np.arange(y_min, y_max, 0.3)*np.std(HJ), orientation='horizontal', alpha=0.7)\n",
    "\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_xlim(np.min(xx_1), np.max(xx_1))\n",
    "    ax.set_ylim(np.min(yy_1), np.max(yy_1))\n",
    "    ax.set_xlabel('Prior Probability', fontweight ='bold', fontsize=11)\n",
    "    ax.set_ylabel('Posterior Probability', fontweight ='bold', fontsize=11)\n",
    "#     axHistx.set_title(taskname)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"figures/\" + taskname +'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_three(taskname, HJ, model_probs, labels, n_neighbors=15, \n",
    "               fig_size=(4.5, 3.5), colors=['green', 'blue', 'red'], legend_labels=['Non-hallucinated', 'Factual Hallucinataion', 'Non-factual Hallucinataion']):\n",
    "    classifier = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='auto')\n",
    "\n",
    "    larray = np.array(labels)\n",
    "    HJ = np.array(HJ)\n",
    "    nmodel_probs = np.array(model_probs)\n",
    "    \n",
    "    pin = nmodel_probs\n",
    "    x_mat = np.vstack([pin / np.std(pin), HJ / np.std(HJ)]).transpose()\n",
    "    y_vec = np.array(labels)\n",
    "    \n",
    "    classifier.fit(x_mat,y_vec)\n",
    "    \n",
    "    # Plot the decision boundary. For that, we will asign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "#     x_min, x_max = x_mat[:, 0].min() - .5, x_mat[:, 0].max() + .5\n",
    "#     y_min, y_max = x_mat[:, 1].min() - .5, x_mat[:, 1].max() + .5\n",
    "    \n",
    "#     h = 0.05\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                          np.arange(y_min, y_max, h))\n",
    "#     Z = classifier.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "    \n",
    "#     xx_1, yy_1 = np.meshgrid(np.arange(x_min, x_max, h) * np.std(pin),\n",
    "#                              np.arange(y_min, y_max, h) * np.std(HJ))\n",
    "    \n",
    "    # Plot color map\n",
    "    cm = plt.cm.RdBu\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "#     ax.contourf(xx_1, yy_1, Z, cmap=cm, alpha=.7)\n",
    "\n",
    "    ax.scatter(np.array(pin)[np.nonzero(larray==0)[0]], np.array(HJ)[np.nonzero(larray==0)[0]], color=colors[0], \n",
    "               edgecolor='black', label=legend_labels[0], marker='s', alpha=0.8)\n",
    "    ax.scatter(np.array(pin)[np.nonzero(larray==1)[0]], np.array(HJ)[np.nonzero(larray==1)[0]], color=colors[1], \n",
    "               edgecolor='black', label=legend_labels[1], alpha=0.8)\n",
    "    ax.scatter(np.array(pin)[np.nonzero(larray==2)[0]], np.array(HJ)[np.nonzero(larray==2)[0]], color=colors[2], \n",
    "               edgecolor='black', label=legend_labels[2], alpha=0.8)\n",
    "    \n",
    "    ax.legend(loc='lower right')\n",
    "#     ax.set_xlim(np.min(xx_1), np.max(xx_1))\n",
    "#     ax.set_ylim(np.min(yy_1), np.max(yy_1))\n",
    "    ax.set_xlabel('CMLM trained on CNN/DM', fontweight ='bold', fontsize=11)\n",
    "    ax.set_ylabel('CMLM trained on XSum', fontweight ='bold', fontsize=11)\n",
    "#     axHistx.set_title(taskname)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"figures/\" + taskname +'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'weight' : 'bold',\n",
    "        'size'   : 8}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_three('entity_distribution_2cmlm', posterior_probabilities, prior_probabilities, true_label, \n",
    "     n_neighbors=10, fig_size=(4.5, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('Hallucination Entity Classification', posterior_probabilities, prior_probabilities, [1 if i == 0 else 0 for i in hallucination_label], \n",
    "     n_neighbors=12, fig_size=(4.5, 3.5), colors=['red', 'blue'], legend_labels=['Hallucinated', 'Non-Hallucinated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('Factual Entity Classification', posterior_probabilities, prior_probabilities, factual_label, n_neighbors=12, \n",
    "     fig_size=(4.5, 3.5), colors=['red', 'blue'], legend_labels=['Non-factual', 'Factual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_KNN(HJ, model_probs, labels, n_neighbors=15):\n",
    "    classifier = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='auto')\n",
    "\n",
    "    larray = np.array(labels)\n",
    "    HJ = np.array(HJ)\n",
    "    nmodel_probs = np.array(model_probs)\n",
    "    \n",
    "    pin = nmodel_probs\n",
    "    x_mat = np.vstack([pin / np.std(pin), HJ / np.std(HJ)]).transpose()\n",
    "#     x_mat = np.vstack([pin, HJ]).transpose()\n",
    "    y_vec = np.array(labels)\n",
    "    \n",
    "    classifier.fit(x_mat, y_vec)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = build_KNN(posterior_probabilities, prior_probabilities, hallucination_label_reverse, n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # source, destination\n",
    "# pickle.dump(knn_classifier, open('classifiers/knn_LM_hallucination_n3.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "\n",
    "# prior\n",
    "fpr, tpr, _ = roc_curve(np.asarray(factual_label), np.asarray(prior_probabilities))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='green',\n",
    "         lw=lw, label='Prior (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# posterior\n",
    "fpr, tpr, _ = roc_curve(np.asarray(factual_label), np.asarray(posterior_probabilities))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='Posterior (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source Expection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_posterior[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_entities, right_entities = [], []\n",
    "for item in prior_posterior:\n",
    "    if item['label'] == 1 and item['posterior'] > 0.8:\n",
    "        if item['prior'] < 0.5:\n",
    "            left_entities.append(item)\n",
    "        else:\n",
    "            right_entities.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(left_entities))\n",
    "print(left_entities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(right_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_source[6824]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(left_entities, open('left_entities.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
