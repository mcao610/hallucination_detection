{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from fairseq.models.bart import BARTModel\n",
    "from utils import read_lines\n",
    "\n",
    "from transformers import BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = json.load(open('../path_config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior_bart = BARTModel.from_pretrained(PATH['bart.large.xsum'],\n",
    "#                                            checkpoint_file='model.pt',\n",
    "#                                            data_name_or_path=PATH['bart.large.xsum'])\n",
    "\n",
    "posterior_bart = BARTModel.from_pretrained(PATH['xsum_cmlm_bos'],\n",
    "                                           checkpoint_file='checkpoint_best.pt',\n",
    "                                           data_name_or_path=PATH['data_name_or_path'])\n",
    "\n",
    "# posterior_bart = BARTModel.from_pretrained(PATH['xsum_cmlm_scratch_cedar_warmup_10000'],\n",
    "#                                            checkpoint_file='checkpoint_best.pt',\n",
    "#                                            data_name_or_path=PATH['data_name_or_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_bart = BARTModel.from_pretrained(PATH['bart.large'],\n",
    "                                       checkpoint_file='model.pt',\n",
    "                                       data_name_or_path=PATH['bart.large'])\n",
    "\n",
    "# prior_bart = BARTModel.from_pretrained(PATH['cnndm_cmlm_cedar'],\n",
    "#                                        checkpoint_file='checkpoint_best.pt',\n",
    "#                                        data_name_or_path=PATH['data_name_or_path'])\n",
    "\n",
    "# prior_bart = BARTModel.from_pretrained(PATH['cnndm_cmlm_scratch_cedar_warmup_20000'],\n",
    "#                                        checkpoint_file='checkpoint_best.pt',\n",
    "#                                        data_name_or_path=PATH['data_name_or_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301\n"
     ]
    }
   ],
   "source": [
    "document_path = PATH['xsum_fariseq'] + '/test.source'\n",
    "target_path = PATH['xsum_fariseq'] + '/test.target'\n",
    "xsum_source = read_lines(document_path)\n",
    "xsum_target = read_lines(target_path)\n",
    "print(len(xsum_source))\n",
    "assert len(xsum_source) == len(xsum_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConditionalSequenceGenerator\n",
    "from utils import prepare_cmlm_inputs, prepare_mlm_inputs, prepare_clm_inputs, get_cmlm_probability, get_prior_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare_clm_inputs, prepare_mlm_inputs, prepare_cmlm_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test One Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 9444\n",
    "\n",
    "source = xsum_source[INDEX]\n",
    "target = 'Twin-to-twin transfusion syndrome (TTTS) is being tracked by a hospital in Cardiff in a bid to save the lives of babies born with the condition.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 35, 'end': 39, 'label': 0, 'type': 'ORG', 'ent': 'TTTS'} - TTTS\n",
      "{'start': 75, 'end': 82, 'label': 2, 'type': 'LOC', 'ent': 'Cardiff'} - Cardiff\n"
     ]
    }
   ],
   "source": [
    "ent_parts = [{'start': 35, 'end': 39, 'label': 0, 'type': 'ORG', 'ent': 'TTTS'},\n",
    "             {'start': 75, 'end': 82, 'label': 2, 'type': 'LOC', 'ent': 'Cardiff'}]\n",
    "\n",
    "for e in ent_parts:\n",
    "    print('{} - {}'.format(e, target[e['start']: e['end']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_model = ConditionalSequenceGenerator(prior_bart)\n",
    "posterior_model = ConditionalSequenceGenerator(posterior_bart)\n",
    "\n",
    "pri_args = prepare_mlm_inputs(source, target, ent_parts)\n",
    "pos_args = prepare_cmlm_inputs(source, target, ent_parts)\n",
    "\n",
    "prior_probs = get_prior_probability(prior_model, pri_args[0], pri_args[1], pri_args[2], pri_args[3])\n",
    "posterior_probs = get_cmlm_probability(posterior_model, pos_args[0], pos_args[1], pos_args[2], pos_args[3])\n",
    "\n",
    "assert len(prior_probs) == len(posterior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- prior: [0.0028667449951171875, 0.0011749267578125]\n",
      "- posterior: [0.77490234375, 0.1083984375]\n"
     ]
    }
   ],
   "source": [
    "print('- prior: {}'.format(prior_probs))\n",
    "print('- posterior: {}'.format(posterior_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read QA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnndm_data = read_jsonl('/home/mcao610/Missing_information/Dataset/QA_dataset/mturk_cnndm_truecase.jsonl')\n",
    "xsum_data = read_jsonl('/home/mcao610/Missing_information/Dataset/QA_dataset/mturk_xsum_truecase.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "235\n"
     ]
    }
   ],
   "source": [
    "print(len(xsum_data))\n",
    "print(len(cnndm_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['article', 'summary_sentences'])\n",
      "[{'sentence': 'Former Leyton orient striker Dean Cox says he will have to wait four months to play in the English football league .', 'responses': [{'worker_id': 2, 'response': 'no'}, {'worker_id': 7, 'response': 'yes'}, {'worker_id': 1, 'response': 'no'}]}]\n"
     ]
    }
   ],
   "source": [
    "print(xsum_data[0].keys())\n",
    "print(xsum_data[3]['summary_sentences'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Probability for Each Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_name(ent_parts, summary):\n",
    "    new_parts = []\n",
    "    for ent in ent_parts:\n",
    "        if ent['label'] != 'PERSON':\n",
    "            new_parts.append(ent)\n",
    "        else:\n",
    "            name_parts = summary[ent['start']: ent['end']].split()\n",
    "            init_start = ent['start']\n",
    "            for p in name_parts:\n",
    "                new_parts.append({'start': init_start, 'end': init_start + len(p), 'label': 'PERSON', 'ent': p})\n",
    "                init_start = init_start + len(p) + 1\n",
    "    return new_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_name([{'start': 0,\n",
    "#    'end': 11,\n",
    "#    'label': 'PERSON',\n",
    "#    'ent': 'Warren Sapp',\n",
    "#    'prior': 0.0003418922424316406,\n",
    "#    'posterior': 0.01715087890625},\n",
    "#   {'start': 89,\n",
    "#    'end': 92,\n",
    "#    'label': 'MONEY',\n",
    "#    'ent': '600',\n",
    "#    'prior': 0.9267578125,\n",
    "#    'posterior': 0.775390625}], \"Warren Sapp admits he paid for oral sex and that ` everyone got naked ' after he ` put $ 600 on the table ' in his hotel room .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [02:59<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "data = xsum_data\n",
    "\n",
    "for INDEX in tqdm(range(len(data))):\n",
    "    source = data[INDEX]['article']\n",
    "    target = data[INDEX]['summary_sentences'][0]['sentence']\n",
    "    ent_parts = nlp(target).to_json()['ents']\n",
    "    for e in ent_parts:\n",
    "        e['ent'] = target[e['start']: e['end']]\n",
    "#     data[INDEX]['ents'] = split_name(ent_parts, target)\n",
    "    data[INDEX]['ents'] = ent_parts\n",
    "    \n",
    "    if len(data[INDEX]['ents']) > 0:\n",
    "        pri_args = prepare_mlm_inputs(source, target, data[INDEX]['ents'])\n",
    "        pos_args = prepare_cmlm_inputs(source, target, data[INDEX]['ents'])\n",
    "        \n",
    "#         if INDEX == 4:\n",
    "#             print(pri_args)\n",
    "#             outputs = prior_model.generate(pri_args[0], tgt_input=None)\n",
    "#             init_input, tokens, token_probs = outputs\n",
    "#             print(tokens)\n",
    "            \n",
    "        prior_probs = get_prior_probability(prior_model, pri_args[0], pri_args[1], pri_args[2], pri_args[3])\n",
    "        posterior_probs = get_cmlm_probability(posterior_model, pos_args[0], pos_args[1], pos_args[2], pos_args[3])\n",
    "\n",
    "        assert len(prior_probs) == len(posterior_probs) == len(data[INDEX]['ents']), \"{};\\n {};\\n {}\".format(prior_probs, posterior_probs, data[INDEX]['ents'])\n",
    "        for i in range(len(prior_probs)):\n",
    "            data[INDEX]['ents'][i]['prior'] = prior_probs[i]\n",
    "            data[INDEX]['ents'][i]['posterior'] = posterior_probs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    for e in d['ents']:\n",
    "        if e['ent'].lower() in d['article'].lower():\n",
    "            e['overlap'] = 1\n",
    "        else:\n",
    "            e['overlap'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': \"Winger Dean Cox says he will have to remain patient as he searches for a new club after leaving league two side Leyton orient by mutual consent . the 29-year-old terminated his contract with the O 's after the transfer window closed , and can not join another EFL side until January . `` I would n't say I 'm in a predicament , but I have never been in this position before , '' Cox told BBC radio London . `` it is not a nice thing for a footballer . I 'm not able to do my job . '' the former Brighton man continued : `` I am going to have to sit it out again for four months before I can kick a ball in the league again . `` I 'll try to make the best of it . it is hard to train on your own and keep yourself motivated but it is something which has got to be done . '' Cox left orient on 1 September after turning down a move to league one Northampton town . having spent six years with the O 's , scoring 59 times in 275 appearances , Cox said he was `` an emotional wreck '' on his departure from Brisbane road . `` I did n't really want to leave but , circumstances being what they were , I felt like I had no choice , '' he said . `` we had come to our conclusion that we were going to go our separate ways . I ca n't really elaborate on it for legal reasons . `` it is a club I will always love . when I finish playing I want to be a manager and if I can go back there and manage one day that would be great . '' Cox , who has only just recovered from a long-term knee injury , is aiming to agree a contract with an EFL club which will commence in January before seeking a short-term deal with a Non-League side to keep up his match fitness . `` I was just getting back in the groove , '' he said . `` if I can get something sorted sooner rather than later League-Wise , then great . `` hopefully the clubs I speak to will understand my situation . I 'm not too proud to play in lower divisions as I need to play . `` come January , I need to be ready to kick on . '' Cox has already held initial negotiations with league two side Crawley town . `` it interests me because they are local to where I am , '' he said . `` it ticks the boxes and I used to play with the captain Jimmy Smith at orient . the manager [ Dermot drummy ] wants attractive attacking football , which is great for me because that is the way I like to play . `` by no means is it a done deal . we have had talks and we 'll see how that goes . '' you can hear an interview with Dean Cox on BBC radio London 's Saturday sport show , which begins at 13:00 BST .\",\n",
       " 'summary_sentences': [{'sentence': 'Former Leyton orient striker Dean Cox says he will have to wait four months to play in the English football league .',\n",
       "   'responses': [{'worker_id': 2, 'response': 'no'},\n",
       "    {'worker_id': 7, 'response': 'yes'},\n",
       "    {'worker_id': 1, 'response': 'no'}]}],\n",
       " 'ents': [{'start': 7,\n",
       "   'end': 13,\n",
       "   'label': 'ORG',\n",
       "   'ent': 'Leyton',\n",
       "   'prior': 0.00041174888610839844,\n",
       "   'posterior': 0.89599609375,\n",
       "   'overlap': 1},\n",
       "  {'start': 29,\n",
       "   'end': 37,\n",
       "   'label': 'PERSON',\n",
       "   'ent': 'Dean Cox',\n",
       "   'prior': 1.2159347534179688e-05,\n",
       "   'posterior': 0.85498046875,\n",
       "   'overlap': 1},\n",
       "  {'start': 64,\n",
       "   'end': 75,\n",
       "   'label': 'DATE',\n",
       "   'ent': 'four months',\n",
       "   'prior': 0.0001017451286315918,\n",
       "   'posterior': 0.5947265625,\n",
       "   'overlap': 1},\n",
       "  {'start': 91,\n",
       "   'end': 98,\n",
       "   'label': 'NORP',\n",
       "   'ent': 'English',\n",
       "   'prior': 0.158935546875,\n",
       "   'posterior': 0.7333984375,\n",
       "   'overlap': 0}]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Factuality Score for Each Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = pickle.load(open('classifiers/knn_mlm_cmlm_3.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_score(responses):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        responses: [{'worker_id': 0, 'response': 'yes'},\n",
    "                    {'worker_id': 8, 'response': 'yes'},\n",
    "                    {'worker_id': 1, 'response': 'no'}]}]\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for r in responses:\n",
    "        scores.append(r['response'] == 'yes')\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_score(ents):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ents: [{'start': 0, 'end': 3, 'label': 'CARDINAL', 'ent': 'Two', 'prior': 0.054473876953125, 'posterior': 0.9091796875},\n",
    "               {'start': 71, 'end': 80, 'label': 'GPE', 'ent': 'edinburgh', 'prior': 0.0, 'posterior': 1.1920928955078125e-07}]\n",
    "    \"\"\"\n",
    "    if len(ents) == 0: return 0.5\n",
    "    posteriors = []\n",
    "    for e in ents:\n",
    "        posteriors.append(e['posterior'])\n",
    "    return min(posteriors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_score(ents):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ents: [{'start': 0, 'end': 3, 'label': 'CARDINAL', 'ent': 'Two', 'prior': 0.054473876953125, 'posterior': 0.9091796875},\n",
    "               {'start': 71, 'end': 80, 'label': 'GPE', 'ent': 'edinburgh', 'prior': 0.0, 'posterior': 1.1920928955078125e-07}]\n",
    "    \"\"\"\n",
    "    if len(ents) == 0: return 0.3\n",
    "    features = []\n",
    "    for e in ents:\n",
    "        features.append([e['posterior'], e['prior'], e['overlap']])\n",
    "    preds = knn.predict(np.array(features))\n",
    "    return np.min(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn_score([{'start': 0, 'end': 3, 'label': 'CARDINAL', 'ent': 'Two', 'prior': 0.054473876953125, 'posterior': 0.9091796875, 'overlap': 1},\n",
    "               {'start': 71, 'end': 80, 'label': 'GPE', 'ent': 'edinburgh', 'prior': 0.0, 'posterior': 1.1920928955078125e-07, 'overlap': 1}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_scores = []\n",
    "model_scores = []\n",
    "knn_scores = []\n",
    "for d in data:\n",
    "    human_scores.append(get_human_score(d['summary_sentences'][0]['responses']))\n",
    "    model_scores.append(get_model_score(d['ents']))\n",
    "    knn_scores.append(get_knn_score(d['ents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0006322860717773438,\n",
       " 0.28955078125,\n",
       " 6.264448165893555e-05,\n",
       " 0.5947265625,\n",
       " 0.5,\n",
       " 0.51513671875,\n",
       " 0.869140625,\n",
       " 0.81884765625,\n",
       " 0.00025343894958496094,\n",
       " 0.00026988983154296875]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6666666666666666,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 1.0,\n",
       " 0.6666666666666666,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 1.0]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_scores[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.25704254970164386, pvalue=5.80225653132512e-05)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(human_scores, model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XSUM posterior: SpearmanrResult(correlation=0.2638292356301218, pvalue=3.615967316333796e-05)\n",
    "# XSUM prior: SpearmanrResult(correlation=0.3213558454590241, pvalue=3.8282097630483723e-07)\n",
    "# XSUM KNN: SpearmanrResult(correlation=0.22219752312978966, pvalue=0.0005392932428629086)\n",
    "# XSUM KNN proba: SpearmanrResult(correlation=0.2134086529828822, pvalue=0.0008993598651778425)\n",
    "\n",
    "# CNN/DM prior: SpearmanrResult(correlation=0.26699069825714755, pvalue=3.374679859317052e-05)\n",
    "# CNN/DM posterior: SpearmanrResult(correlation=0.21077493981288759, pvalue=0.00115208952067579)\n",
    "# CNN/DM KNN: SpearmanrResult(correlation=0.1441617378794903, pvalue=0.027123968278036766)\n",
    "# CNN/DM KNN proba: SpearmanrResult(correlation=0.100354334221829, pvalue=0.12501122321386574)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2679415408591233, 2.6979949254603694e-05)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(human_scores, knn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
