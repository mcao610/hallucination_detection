{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "from utils import read_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = json.load(open('../path_config.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = PATH['xsum_fariseq'] + '/test.source'\n",
    "target_path = PATH['xsum_fariseq'] + '/test.target'\n",
    "xsum_source = read_lines(document_path)\n",
    "xsum_target = read_lines(target_path)\n",
    "print(len(xsum_source))\n",
    "assert len(xsum_source) == len(xsum_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Annotated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('../data/annotated_with_probability.json', 'r'))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior/Posterior Distribution Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from draw import plot_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_posterior = []\n",
    "for d in data:\n",
    "    for e in d['ents']:\n",
    "        e['id'] = d['id']\n",
    "        e['prior'] = e['xsum_cmlm_scratch_cedar_warmup_20000']\n",
    "        e['posterior'] = e['xsum_cmlm_bos']\n",
    "        prior_posterior.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 0],\n",
    "    [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 1],\n",
    "    [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 2],\n",
    "    [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 3]\n",
    "]\n",
    "labels = ['Non-hallucination', 'Hallucination True', 'Hallucination False', 'Intrinsic Hallucination']\n",
    "plot_scatter(input_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare CMLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 10\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(7.0, 2.0))\n",
    "\n",
    "# priors_0 = [p['prior'] for p in prior_posterior if p['label'] == 0]\n",
    "# posteriors_0 = [p['posterior'] for p in prior_posterior if p['label'] == 0]\n",
    "# _, bins, _ = ax0.hist(priors_0, n_bins, density=False, histtype='bar', color='blue', label=r'$\\textrm{CMLM}_\\textrm{CNN/DM}$', edgecolor='blue', alpha=0.55)\n",
    "# ax0.hist(posteriors_0, bins=bins + 0.015, density=False, histtype='bar', color='red', label=r'$\\textrm{CMLM}_\\textsc{XSum}$', edgecolor='red', alpha=0.35)\n",
    "# ax0.set_ylabel('Count', fontsize=13)\n",
    "# ax0.set_title('Non-hallucinated Entities', fontsize=13)\n",
    "\n",
    "priors_0 = [p['prior'] for p in prior_posterior if p['label'] == 0]\n",
    "posteriors_0 = [p['posterior'] for p in prior_posterior if p['label'] == 0]\n",
    "_, bins, _ = ax0.hist(priors_0, n_bins, density=False, histtype='bar', color='blue', label='CMLM trained on CNN/DM', edgecolor='blue', alpha=0.55)\n",
    "ax0.hist(posteriors_0, bins=bins + 0.015, density=False, histtype='bar', color='red', label='CMLM trained on XSum', edgecolor='red', alpha=0.35)\n",
    "ax0.set_ylabel('Count', fontsize=12)\n",
    "ax0.set_title('Non-hallucinated Entities', fontsize=12)\n",
    "\n",
    "priors_1 = [p['prior'] for p in prior_posterior if p['label'] == 1]\n",
    "posteriors_1 = [p['posterior'] for p in prior_posterior if p['label'] == 1]\n",
    "_, bins, _ = ax1.hist(priors_1, n_bins, density=False, histtype='bar', color='blue', label='CMLM (CNN/DM)', edgecolor='blue', alpha=0.55)\n",
    "ax1.hist(posteriors_1, bins=bins + 0.015, density=False, histtype='bar', color='red', label='CMLM (XSum)', edgecolor='red', alpha=0.35)\n",
    "ax1.legend(prop={'size': 11})\n",
    "ax1.set_title('Factul Hallucinations', fontsize=12)\n",
    "\n",
    "fig.text(0.5, -0.05, 'Posterior Probability', ha='center', fontsize=12)\n",
    "fig.tight_layout()\n",
    "\n",
    "# fig.text(0.0, 0.5, 'Count', va='center', rotation='vertical', fontsize=12)\n",
    "plt.savefig(\"figures/\" + 'hist_2cmlm' +'.pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 10\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, ncols=1, figsize=(5.0, 4.0))\n",
    "\n",
    "priors_0 = [p['prior'] for p in prior_posterior if p['label'] == 0]\n",
    "posteriors_0 = [p['posterior'] for p in prior_posterior if p['label'] == 0]\n",
    "_, bins, _ = ax0.hist(priors_0, n_bins, density=True, histtype='bar', color='blue', label='CMLM trained on CNN/DM', edgecolor='blue', alpha=0.55)\n",
    "ax0.hist(posteriors_0, bins=bins + 0.015, density=True, histtype='bar', color='red', label='CMLM trained on XSum', edgecolor='red', alpha=0.35)\n",
    "# ax0.set_ylabel('Count', fontsize=12)\n",
    "ax0.set_title('Non-hallucinated Entities', fontsize=12)\n",
    "\n",
    "priors_1 = [p['prior'] for p in prior_posterior if p['label'] == 1]\n",
    "posteriors_1 = [p['posterior'] for p in prior_posterior if p['label'] == 1]\n",
    "_, bins, _ = ax1.hist(priors_1, n_bins, density=True, histtype='bar', color='blue', label='CMLM trained on CNN/DM', edgecolor='blue', alpha=0.55)\n",
    "ax1.hist(posteriors_1, bins=bins + 0.015, density=True, histtype='bar', color='red', label='CMLM trained on XSum', edgecolor='red', alpha=0.35)\n",
    "ax0.legend(prop={'size': 11})\n",
    "ax1.set_title('Factul Hallucinations', fontsize=12)\n",
    "\n",
    "fig.text(0.5, -0.05, 'Posterior Probability', ha='center', fontsize=12)\n",
    "fig.tight_layout()\n",
    "# if save_fig:\n",
    "#     plt.savefig(\"figures/\" + taskname +'.pdf', bbox_inches=\"tight\")\n",
    "\n",
    "fig.text(0.0, 0.5, 'Count', va='center', rotation='vertical', fontsize=12)\n",
    "plt.savefig(\"figures/\" + 'hist_2cmlm_vertical' +'.pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_entities = []\n",
    "# for e in prior_posterior:\n",
    "#     if e['label'] == 1:\n",
    "#         if e['prior'] > 1e-5 and math.log(e['posterior'] / e['prior']) > 5:\n",
    "#             selected_entities.append(e)\n",
    "#         if e['prior'] > 0. and math.log(e['posterior'] / e['prior']) < 0:\n",
    "#             selected_entities.append(e)\n",
    "#         elif e['posterior'] - e['prior'] > 0.5:\n",
    "#             selected_entities.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(selected_entities))\n",
    "# print(selected_entities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(selected_entities, open('sigma_entities.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Average Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from draw import plot_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(3):\n",
    "    posteriors = [p['prior'] for p in prior_posterior if p['label'] == l]\n",
    "    print('- label {}: {}'.format(l, -math.log(sum(posteriors) / len(posteriors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0001\n",
    "posteriors = [[], [], []]\n",
    "for l in range(3):\n",
    "    for p in prior_posterior:\n",
    "        if p['label'] == l and p['posterior'] > threshold:\n",
    "            posteriors[l].append(-math.log(p['posterior']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1e-7\n",
    "priors= [[], [], []]\n",
    "for l in range(3):\n",
    "    for p in prior_posterior:\n",
    "        if p['label'] == l and p['prior'] > threshold:\n",
    "            priors[l].append(-math.log(p['prior']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist('histogram', posteriors, priors, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_posterior[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label, factual_label, hallucination_label = [], [], []\n",
    "prior_probabilities, posterior_probabilities = [], []\n",
    "\n",
    "for p in prior_posterior:\n",
    "    if p['label'] is not None and p['label'] != 3:\n",
    "        if p['label'] == 0 or p['label'] == 1:\n",
    "            factual_label.append(1)\n",
    "        elif p['label'] == 2:\n",
    "            factual_label.append(0)\n",
    "        else:\n",
    "            raise Exception(\"ERROR! {}\".format(p['label']))\n",
    "            \n",
    "        if p['label'] == 0:\n",
    "            hallucination_label.append(0)\n",
    "        elif p['label'] == 2 or p['label'] == 1:\n",
    "            hallucination_label.append(1)\n",
    "        else:\n",
    "            raise Exception(\"ERROR! {}\".format(p['label']))\n",
    "            \n",
    "        true_label.append(p['label'])\n",
    "        prior_probabilities.append(p['prior'])\n",
    "        posterior_probabilities.append(p['posterior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_baseline_preds = []\n",
    "overlap_preds = []\n",
    "\n",
    "for p in prior_posterior:\n",
    "    if p['label'] is not None and p['label'] != 3:\n",
    "        source = xsum_source[p['id']]\n",
    "\n",
    "        if p['ent'].lower() in source.lower():\n",
    "            overlap_preds.append(1)\n",
    "        else:\n",
    "            overlap_preds.append(0)\n",
    "\n",
    "        if p['posterior'] > p['prior']:\n",
    "            lm_baseline_preds.append(1)\n",
    "        else:\n",
    "            lm_baseline_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(factual_label, overlap_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], overlap_preds, \n",
    "                            target_names=['Non-hallucinated', 'Hallucinated'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(factual_label, lm_baseline_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], lm_baseline_preds, \n",
    "                            target_names=['Non-hallucinated', 'Hallucinated'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from sklearn import neighbors\n",
    "from draw import plot, plot_three, plot_three_with_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_error(prior_probs, posterior_probs, labels, n_neighbors=15):\n",
    "    assert len(prior_probs) == len(posterior_probs) == len(labels)\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(len(prior_probs)):\n",
    "        train_features, train_labels = [], []\n",
    "        for j in range(len(prior_probs)):\n",
    "            if j != i:\n",
    "                train_features.append([prior_probs[j], posterior_probs[j]])\n",
    "                train_labels.append(labels[j])\n",
    "    \n",
    "        classifier = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='auto')\n",
    "\n",
    "        x_mat = np.array(train_features)\n",
    "        y_vec = np.array(train_labels)\n",
    "        classifier.fit(x_mat, y_vec)\n",
    "        \n",
    "        test_features = np.array([[prior_probs[i], posterior_probs[i]]])\n",
    "        Z = classifier.predict(test_features)\n",
    "        preds.append(Z[0])\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_label_reverse = [1 if i == 0 else 0 for i in hallucination_label]\n",
    "knn_preds = leave_one_out_error(prior_probabilities, posterior_probabilities, hallucination_label_reverse, n_neighbors=16)\n",
    "print(classification_report(hallucination_label_reverse, knn_preds, target_names=['Hallucinated', 'Non-hallucinated'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_preds = leave_one_out_error(prior_probabilities, posterior_probabilities, factual_label, n_neighbors=12)\n",
    "print(classification_report(factual_label, knn_preds, target_names=['Non-Factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'weight' : 'normal',\n",
    "        'size'   : 8}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_three_with_boundary('entity_distribution_2cmlm',\n",
    "                         posterior_probabilities, prior_probabilities, true_label,\n",
    "                         colors=['blue', 'darkgreen', 'red'],\n",
    "                         legend_labels=['Non-hallucinated', 'Factual Hallucinataion', 'Non-factual Hallucinataion'],\n",
    "                         x_label='CMLM trained on CNN/DM',\n",
    "                         y_label='CMLM trained on XSum',\n",
    "                         n_neighbors=16,\n",
    "                         fig_size=(4.5, 3.5),\n",
    "                         interval=0.25, h=0.05,\n",
    "                         save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_three('entity_distribution_mlm_cmlm',\n",
    "           posterior_probabilities, prior_probabilities, true_label,\n",
    "           colors=['blue','darkgreen', 'red'],\n",
    "           x_label='Prior Probability',\n",
    "           y_label='Posterior Probability',\n",
    "           legend_labels=['Non-hallucinated', 'Factual Hallucinataion', 'Non-factual Hallucinataion'],\n",
    "           n_neighbors=10,\n",
    "           fig_size=(4.5, 3.5),\n",
    "           save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('Hallucination Entity Classification',\n",
    "     posterior_probabilities, prior_probabilities, [1 if i == 0 else 0 for i in hallucination_label], \n",
    "     n_neighbors=12, fig_size=(4.5, 3.5), colors=['red', 'blue'], legend_labels=['Hallucinated', 'Non-Hallucinated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('compare_mlm_and_cmlm', posterior_probabilities, prior_probabilities, factual_label, n_neighbors=12, \n",
    "     fig_size=(4.5, 3.5), colors=['red', 'blue'], legend_labels=['Non-factual', 'Factual'],\n",
    "     x_label='CLM Posterior Probability', y_label='CMLM Posterior Probability', save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_KNN(posteriors, priors, labels, n_neighbors=15):\n",
    "    classifier = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='auto')\n",
    "\n",
    "    priors = np.array(priors)\n",
    "    posteriors = np.array(posteriors)\n",
    "    \n",
    "#     x_mat = np.vstack([posteriors / np.std(posteriors), priors / np.std(priors)]).transpose()\n",
    "    x_mat = np.vstack([posteriors, priors]).transpose()\n",
    "    y_vec = np.array(labels)\n",
    "    \n",
    "    classifier.fit(x_mat, y_vec)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = build_KNN(posterior_probabilities, prior_probabilities, hallucination_label_reverse, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn_classifier.predict(np.array(np.vstack([posterior_probabilities, prior_probabilities]).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(hallucination_label_reverse, knn_preds, target_names=['Non-Factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source, destination\n",
    "# pickle.dump(knn_classifier, open('classifiers/knn_mlm_cmlm_hallucination.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from draw import draw_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2, p3, p4, p5, p6, p7 = [], [], [], [], [], [], []\n",
    "\n",
    "for p in prior_posterior:\n",
    "    if p['label'] is not None and p['label'] != 3:\n",
    "        p1.append(p['bart.large'])\n",
    "        p2.append(p['xsum_cmlm_bos'])\n",
    "        p3.append(p['xsum_cmlm_scratch_cedar_warmup_10000'])\n",
    "        p4.append(p['cnndm_cmlm_cedar'])\n",
    "        p5.append(p['cnndm_cmlm_scratch_cedar_warmup_10000'])\n",
    "        p6.append(p['bart.large.xsum'])\n",
    "        p7.append(p['bart.large.cnn'])\n",
    "\n",
    "assert len(p1) == len(factual_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_auc(factual_label,\n",
    "         [p1, p2, p3, p4, p5, p6, p7],\n",
    "         ['MLM', 'CMLM on XSum', 'CMLM on XSum scratch', 'CMLM on CNN/DM', 'CMLM on CNN/DM scratch', 'CLM on XSum', 'CLM on CNN/DM'],\n",
    "         ['darkorange', 'green', 'red', 'blue', 'pink', 'aqua', 'tab:purple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_auc(factual_label,\n",
    "         [p2, p6, p4, p7],\n",
    "         ['CMLM on XSum', 'CLM on XSum', 'CMLM on CNN/DM', 'CLM on CNN/DM'],\n",
    "         ['darkorange', 'green', 'red', 'blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     'start': 61,\n",
    "#     'end': 74,\n",
    "#     'label': 2,\n",
    "#     'type': 'CARDINAL',\n",
    "#     'ent': 'more than 100',\n",
    "#     'bart.large': 0.024139404296875,\n",
    "#     'xsum_cmlm_bos': 0.0843505859375,\n",
    "#     'cnndm_cmlm_cedar': 0.01030731201171875,\n",
    "#     'bart.large.xsum': 0.05517578125,\n",
    "#     'cnndm_cmlm_scratch_cedar_warmup_20000': 1.6808509826660156e-05,\n",
    "#     'xsum_cmlm_scratch_cedar_warmup_10000': 0.00960540771484375,\n",
    "#     'cnndm_cmlm_scratch_cedar_warmup_10000': 4.7087669372558594e-05,\n",
    "#     'xsum_cmlm_scratch_cedar_warmup_20000': 0.003948211669921875\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
