{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clean-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-mortality",
   "metadata": {},
   "source": [
    "#### Read Original Google Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "familiar-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "factuality_data = json.load(open('../data/xsum_hallucination_annotations/factuality_annotations_xsum_summaries.json'))\n",
    "hallucination_data = json.load(open('../data/xsum_hallucination_annotations/hallucination_annotations_xsum_summaries.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "least-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5597\n",
      "11185\n"
     ]
    }
   ],
   "source": [
    "print(len(factuality_data))\n",
    "print(len(hallucination_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "substantial-booth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbcid': 33517280,\n",
       " 'system': 'TranS2S',\n",
       " 'summary': 'five men have been charged after a protest at heathrow airport led to the closure of a runway at heathrow airport.',\n",
       " 'is_factual': 'no',\n",
       " 'worker_id': 'wid_1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factuality_data[2330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "immediate-florist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbcid': 34687720,\n",
       " 'system': 'BERTS2S',\n",
       " 'summary': 'rory mcilroy will take a one-shot lead into the final round of the wgc-hsbc champions after carding a three-under',\n",
       " 'hallucination_type': 'extrinsic',\n",
       " 'hallucinated_span': 'rory mcilroy will take a one-shot lead into the final round of the wgc-hsbc champions after carding a three-under',\n",
       " 'worker_id': 'wid_0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-health",
   "metadata": {},
   "source": [
    "#### Read Calculated Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "scheduled-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_data_with_proba = json.load(open('../data/Maynez_entity_data_with_prob.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expressed-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(google_data_with_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "disturbed-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bbcid in google_data_with_proba:\n",
    "    for system in google_data_with_proba[bbcid]:\n",
    "        for e in google_data_with_proba[bbcid][system]['ents']:\n",
    "            if 'cnndm_cmlm_cedar' in e and 'xsum_cmlm_bos' in e:\n",
    "                e['prior'] = e['bart.large']\n",
    "                e['posterior'] = e['xsum_cmlm_bos']\n",
    "            else:\n",
    "                e['prior'] = None\n",
    "                e['posterior'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_data_with_proba['34687720']['Gold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-potential",
   "metadata": {},
   "source": [
    "#### Claculate Factuality Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "factuality_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "factuality = {}\n",
    "for i, f in enumerate(factuality_data):\n",
    "    if f['bbcid'] not in factuality:\n",
    "        factuality[f['bbcid']] = {}\n",
    "    if f['system'] not in factuality[f['bbcid']]:\n",
    "        factuality[f['bbcid']][f['system']] = []\n",
    "        \n",
    "    if f['is_factual'] == 'yes':\n",
    "        factuality[f['bbcid']][f['system']].append(True)\n",
    "    elif f['is_factual'] == 'no':\n",
    "        factuality[f['bbcid']][f['system']].append(False)\n",
    "    elif f['is_factual'] is None:\n",
    "        factuality[f['bbcid']][f['system']].append(False)\n",
    "    else:\n",
    "        print(i)\n",
    "        raise Exception('Unkown Label: {}'.format(f['is_factual']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination = {}\n",
    "for h in hallucination_data:\n",
    "    if h['bbcid'] not in hallucination:\n",
    "        hallucination[h['bbcid']] = {}\n",
    "    if h['system'] not in hallucination[h['bbcid']]:\n",
    "        hallucination[h['bbcid']][h['system']] = []\n",
    "    \n",
    "    if h['hallucination_type'] == 'extrinsic' and len(h['hallucinated_span']) < len(h['summary']):\n",
    "        hallucination[h['bbcid']][h['system']].append(h['hallucinated_span'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination[34687720]['BERTS2S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity in hallucination span (extrinsic), and summary false: false-hallucination\n",
    "# entity in hallucination span (extrinsic), and summary true: true-hallucnination\n",
    "# entity not in hallucination span and summary true: non-hallucination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-victor",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_factual(scores):\n",
    "    if None in scores: return False\n",
    "#     if len(scores) == sum(scores):\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "    if sum(scores) * 2 >= len(scores):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hallucinated(entity, spans):\n",
    "    for s in spans:\n",
    "        if entity in s:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual_label, hallucination_label, posterior_label = [], [], []\n",
    "prior_probs, posterior_probs = [], []\n",
    "overlap_preds, threshold_preds = [], []\n",
    "\n",
    "for bbcid in google_data_with_proba:\n",
    "    for system in google_data_with_proba[bbcid]:\n",
    "        if int(bbcid) not in factuality or system not in factuality[int(bbcid)]: continue\n",
    "        if system not in ['BERTS2S']: continue\n",
    "    \n",
    "        for e in google_data_with_proba[bbcid][system]['ents']:\n",
    "            if 'posterior' not in e or e['posterior'] is None: continue\n",
    "            \n",
    "            is_factual = check_factual(factuality[int(bbcid)][system])\n",
    "            is_hallucinated = check_hallucinated(e['ent'], hallucination[int(bbcid)][system])\n",
    "            is_entity_in_document = e['ent'].lower() in read_document(int(bbcid), '/home/mcao610/scratch/summarization/XSum/xsum-preprocessed/document/').lower()\n",
    "\n",
    "            if is_factual and is_hallucinated:\n",
    "                factual_label.append(1)\n",
    "                hallucination_label.append(1)\n",
    "            elif is_factual and not is_hallucinated:\n",
    "                factual_label.append(1)\n",
    "                hallucination_label.append(0)\n",
    "            elif (not is_factual) and is_hallucinated:\n",
    "                factual_label.append(0)\n",
    "                hallucination_label.append(1)\n",
    "            elif (not is_factual) and (not is_hallucinated):\n",
    "                factual_label.append(1)\n",
    "                hallucination_label.append(0)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            prior_probs.append(e['prior'])\n",
    "            posterior_probs.append(e['posterior'])\n",
    "            \n",
    "            if e['posterior'] > e['prior']:\n",
    "                posterior_label.append(1)\n",
    "            else:\n",
    "                posterior_label.append(0)\n",
    "                \n",
    "            if is_entity_in_document:\n",
    "                overlap_preds.append(1)\n",
    "            else:\n",
    "                overlap_preds.append(0)\n",
    "                \n",
    "            if e['posterior'] > 0.4:\n",
    "                threshold_preds.append(1)\n",
    "            else:\n",
    "                threshold_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(factual_label))\n",
    "assert len(factual_label) == len(posterior_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-thomson",
   "metadata": {},
   "source": [
    "#### Draw Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from draw import plot_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_posterior = []\n",
    "for pos, pri, f, h in zip(posterior_probs, prior_probs, factual_label, hallucination_label):\n",
    "    my_label = -1\n",
    "    if f == 1 and h == 1:\n",
    "        my_label = 1\n",
    "    elif f == 0 and h == 1:\n",
    "        my_label = 2\n",
    "    elif f == 1 and h == 0:\n",
    "        my_label = 0\n",
    "    assert my_label != -1\n",
    "    prior_posterior.append({'prior': pri, 'posterior': pos, 'label': my_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 0],\n",
    "    [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 1],\n",
    "    [(p['prior'], p['posterior']) for p in prior_posterior if p['label'] == 2]\n",
    "]\n",
    "labels = ['Non-hallucination', 'Hallucination True', 'Hallucination False']\n",
    "plot_scatter(input_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-darwin",
   "metadata": {},
   "source": [
    "#### Overlap Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(factual_label, threshold_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(factual_label, overlap_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], overlap_preds, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-burst",
   "metadata": {},
   "source": [
    "#### LM-based Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(factual_label, posterior_label, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], posterior_label, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-slave",
   "metadata": {},
   "source": [
    "#### Load KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(knn_model, posteriors, priors):\n",
    "    posteriors = np.array(posteriors)\n",
    "    priors = np.array(priors)\n",
    "\n",
    "    x_mat = np.vstack([posteriors / np.std(posteriors), priors / np.std(priors)]).transpose()\n",
    "    # x_mat = np.vstack([posteriors, priors]).transpose()\n",
    "\n",
    "    return knn_model.predict(x_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "knn_model = pickle.load(open('classifiers/knn_mlm_clm.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict(knn_model, posterior_probs, prior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([1 if i == 0 else 0 for i in hallucination_label], prediction, target_names=['Non-hallutionated', 'Hallutionated'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM + KNN:\n",
    "#                    precision    recall  f1-score   support\n",
    "\n",
    "# Non-hallutionated     0.1417    0.3926    0.2083       135\n",
    "#     Hallutionated     0.9123    0.7266    0.8089      1174\n",
    "\n",
    "#          accuracy                         0.6921      1309\n",
    "#         macro avg     0.5270    0.5596    0.5086      1309\n",
    "#      weighted avg     0.8328    0.6921    0.7470      1309\n",
    "\n",
    "# Main model (n=5):\n",
    "#                    precision    recall  f1-score   support\n",
    "\n",
    "# Non-hallutionated     0.1545    0.3778    0.2194       135\n",
    "#     Hallutionated     0.9142    0.7624    0.8314      1174\n",
    "\n",
    "#          accuracy                         0.7227      1309\n",
    "#         macro avg     0.5344    0.5701    0.5254      1309\n",
    "#      weighted avg     0.8359    0.7227    0.7683      1309\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(factual_label, prediction, target_names=['Non-factual', 'Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM + KNN (n=4)\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#  Non-factual     0.1389    0.3200    0.1937       125\n",
    "#      Factual     0.9167    0.7905    0.8490      1184\n",
    "\n",
    "#     accuracy                         0.7456      1309\n",
    "#    macro avg     0.5278    0.5553    0.5213      1309\n",
    "# weighted avg     0.8425    0.7456    0.7864      1309\n",
    "\n",
    "# Main Model (n=4)\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#  Non-factual     0.1373    0.2240    0.1702       125\n",
    "#      Factual     0.9122    0.8514    0.8807      1184\n",
    "\n",
    "#     accuracy                         0.7914      1309\n",
    "#    macro avg     0.5247    0.5377    0.5255      1309\n",
    "# weighted avg     0.8382    0.7914    0.8129      1309"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
