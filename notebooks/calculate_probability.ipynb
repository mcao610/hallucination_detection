{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from fairseq.models.bart import BARTModel\n",
    "from utils import read_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = json.load(open('../path_config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior_bart = BARTModel.from_pretrained(PATH['bart.large.xsum'],\n",
    "#                                            checkpoint_file='model.pt',\n",
    "#                                            data_name_or_path=PATH['bart.large.xsum'])\n",
    "\n",
    "# posterior_bart = BARTModel.from_pretrained(PATH['bart.large.cnn'],\n",
    "#                                            checkpoint_file='model.pt',\n",
    "#                                            data_name_or_path=PATH['bart.large.cnn'])\n",
    "\n",
    "posterior_bart = BARTModel.from_pretrained(PATH['xsum_cmlm_bos'],\n",
    "                                           checkpoint_file='checkpoint_best.pt',\n",
    "                                           data_name_or_path=PATH['data_name_or_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_bart = BARTModel.from_pretrained(PATH['bart.large'],\n",
    "                                       checkpoint_file='model.pt',\n",
    "                                       data_name_or_path=PATH['bart.large'])\n",
    "\n",
    "# prior_bart = BARTModel.from_pretrained(PATH['cnndm_cmlm_cedar'],\n",
    "#                                        checkpoint_file='checkpoint_best.pt',\n",
    "#                                        data_name_or_path=PATH['data_name_or_path'])\n",
    "\n",
    "# prior_bart = BARTModel.from_pretrained(PATH['cnndm_cmlm_scratch_cedar_warmup_10000'],\n",
    "#                                        checkpoint_file='checkpoint_best.pt',\n",
    "#                                        data_name_or_path=PATH['data_name_or_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301\n"
     ]
    }
   ],
   "source": [
    "document_path = PATH['xsum_fariseq'] + '/test.source'\n",
    "target_path = PATH['xsum_fariseq'] + '/test.target'\n",
    "xsum_source = read_lines(document_path)\n",
    "xsum_target = read_lines(target_path)\n",
    "print(len(xsum_source))\n",
    "assert len(xsum_source) == len(xsum_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test One Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "\n",
    "from model import ConditionalSequenceGenerator\n",
    "from utils import prepare_cmlm_inputs, prepare_mlm_inputs, prepare_clm_inputs, get_cmlm_probability, get_probability, get_probability_parallel\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_model = ConditionalSequenceGenerator(prior_bart)\n",
    "posterior_model = ConditionalSequenceGenerator(posterior_bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_filling(model, src_input, tgt_input=None):\n",
    "    \"\"\"\n",
    "    Filling the mask in sentence(s).\n",
    "    \"\"\"\n",
    "    input_ids, lengths = model.tokenize_with_mask(src_input)\n",
    "\n",
    "    target_ids = None\n",
    "    if tgt_input is not None:\n",
    "        assert len(src_input) == len(tgt_input), \"source & target length should match.\"\n",
    "        target_ids, _ = model.tokenize(tgt_input, left_pad=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_output = model.encode_sequence(input_ids, lengths)\n",
    "        decoder_output = model.decode_sequence(encoder_output, \n",
    "                                               target_ids=target_ids,\n",
    "                                               prefix_tokens=[2, 0])\n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior_probability(generator, src_input, tgt_input, position, entity):\n",
    "    \"\"\"Tokenize input with a special <mask> token.\"\"\"\n",
    "    assert len(src_input) == len(tgt_input), \"source & target length should match.\"\n",
    "    decoder_output = mask_filling(generator, src_input, tgt_input)\n",
    "    init_input, tokens, token_probs = decoder_output\n",
    "    \n",
    "    probs = []\n",
    "    for p, tok, tokp, e in zip(position, tokens, token_probs, entity):\n",
    "        probs.append(get_probability(p, tok, tokp, e).item())\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 9185\n",
    "\n",
    "source = xsum_source[INDEX]\n",
    "target = 'A baby pine marten has been captured on camera for the first time in Wales as part of a campaign to reintroduce the animal to Ceredigion.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 55, 'end': 60, 'label': 'ORDINAL'} - first\n",
      "{'start': 69, 'end': 74, 'label': 'GPE'} - Wales\n"
     ]
    }
   ],
   "source": [
    "# ent_parts = [{'start': 35, 'end': 39, 'label': 0, 'type': 'ORG', 'ent': 'TTTS'},\n",
    "#              {'start': 75, 'end': 82, 'label': 2, 'type': 'LOC', 'ent': 'Cardiff'}]\n",
    "\n",
    "ent_parts = nlp(target).to_json()['ents']\n",
    "\n",
    "for e in ent_parts:\n",
    "    print('{} - {}'.format(e, target[e['start']: e['end']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_args = prepare_mlm_inputs(source, target, ent_parts)\n",
    "pos_args = prepare_cmlm_inputs(source, target, ent_parts)\n",
    "\n",
    "# prior_probs = get_prior_probability(prior_model, pri_args[0], pri_args[1], pri_args[2], pri_args[3])\n",
    "prior_probs = get_probability_parallel(prior_model, pri_args[0], pri_args[1], pri_args[2], pri_args[3], mask_filling=True)\n",
    "posterior_probs = get_probability_parallel(posterior_model, pos_args[0], pos_args[1], pos_args[2], pos_args[3])\n",
    "\n",
    "assert len(prior_probs) == len(posterior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- prior: [0.95849609375, 0.1553955078125]\n",
      "- posterior: [0.91455078125, 0.85498046875]\n"
     ]
    }
   ],
   "source": [
    "print('- prior: {}'.format(prior_probs))\n",
    "print('- posterior: {}'.format(posterior_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A baby pine marten has been captured on camera for the <mask> time in Wales as part of a campaign to reintroduce the animal to Ceredigion.',\n",
       "  'A baby pine marten has been captured on camera for the first time in <mask> as part of a campaign to reintroduce the animal to Ceredigion.'],\n",
       " ['A baby pine marten has been captured on camera for the first time in Wales as part of a campaign to reintroduce the animal to Ceredigion.',\n",
       "  'A baby pine marten has been captured on camera for the first time in Wales as part of a campaign to reintroduce the animal to Ceredigion.'],\n",
       " [(55, 60), (69, 74)],\n",
       " ['first', 'Wales'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pri_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open('../data/annotated_with_probability_200.json', 'r'))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 10943,\n",
       " 'pred': \"A powerful cyclone has killed at least 11 people and injured more than 100 in Vanuatu, the Pacific nation's president has said.\",\n",
       " 'ents': [{'start': 30,\n",
       "   'end': 41,\n",
       "   'label': 2,\n",
       "   'type': 'CARDINAL',\n",
       "   'ent': 'at least 11',\n",
       "   'bart.large': 0.0215301513671875,\n",
       "   'xsum_cmlm_bos': 0.02984619140625,\n",
       "   'bart.large.xsum': 0.0200347900390625,\n",
       "   'cnndm_cmlm_cedar': 0.007183074951171875,\n",
       "   'cnndm_cmlm_scratch_cedar_warmup_10000': 1.9073486328125e-06,\n",
       "   'xsum_cmlm_scratch_cedar_warmup_20000': 0.092529296875},\n",
       "  {'start': 61,\n",
       "   'end': 74,\n",
       "   'label': 2,\n",
       "   'type': 'CARDINAL',\n",
       "   'ent': 'more than 100',\n",
       "   'bart.large': 0.05804443359375,\n",
       "   'xsum_cmlm_bos': 0.0843505859375,\n",
       "   'bart.large.xsum': 0.06317138671875,\n",
       "   'cnndm_cmlm_cedar': 0.01030731201171875,\n",
       "   'cnndm_cmlm_scratch_cedar_warmup_10000': 4.7087669372558594e-05,\n",
       "   'xsum_cmlm_scratch_cedar_warmup_20000': 0.003948211669921875},\n",
       "  {'start': 78,\n",
       "   'end': 85,\n",
       "   'label': 0,\n",
       "   'type': 'GPE',\n",
       "   'ent': 'Vanuatu',\n",
       "   'bart.large': 0.00024771690368652344,\n",
       "   'xsum_cmlm_bos': 0.857421875,\n",
       "   'bart.large.xsum': 0.736328125,\n",
       "   'cnndm_cmlm_cedar': 0.8759765625,\n",
       "   'cnndm_cmlm_scratch_cedar_warmup_10000': 0.0,\n",
       "   'xsum_cmlm_scratch_cedar_warmup_20000': 0.0029964447021484375},\n",
       "  {'start': 91,\n",
       "   'end': 98,\n",
       "   'label': 1,\n",
       "   'type': 'LOC',\n",
       "   'ent': 'Pacific',\n",
       "   'bart.large': 0.59765625,\n",
       "   'xsum_cmlm_bos': 0.9716796875,\n",
       "   'bart.large.xsum': 0.59375,\n",
       "   'cnndm_cmlm_cedar': 0.52880859375,\n",
       "   'cnndm_cmlm_scratch_cedar_warmup_10000': 0.0004143714904785156,\n",
       "   'xsum_cmlm_scratch_cedar_warmup_20000': 0.295166015625}],\n",
       " 'hallucinations': ['killed at least 11 people and injured more than 100',\n",
       "  \"the Pacific nation's president has said.\"]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:40<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "for INDEX in tqdm(range(len(data))):\n",
    "    source = xsum_source[data[INDEX]['id']]\n",
    "    target = data[INDEX]['pred']\n",
    "    \n",
    "    pri_args = prepare_cmlm_inputs(source, target, data[INDEX]['ents'])\n",
    "    pos_args = prepare_cmlm_inputs(source, target, data[INDEX]['ents'])\n",
    "\n",
    "    prior_probs = get_cmlm_probability(prior_model, pri_args[0], pri_args[1], pri_args[2], pri_args[3])\n",
    "    posterior_probs = get_cmlm_probability(posterior_model, pos_args[0], pos_args[1], pos_args[2], pos_args[3])\n",
    "    \n",
    "    assert len(prior_probs) == len(posterior_probs) == len(data[INDEX]['ents']), \"{};\\n {};\\n {}\".format(prior_probs, posterior_probs, data[INDEX]['ents'])\n",
    "    for i in range(len(prior_probs)):\n",
    "        data[INDEX]['ents'][i]['cnndm_cmlm_scratch_cedar_warmup_10000'] = prior_probs[i]\n",
    "        data[INDEX]['ents'][i]['xsum_cmlm_scratch_cedar_warmup_20000'] = posterior_probs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/annotated_with_probability_200.json', 'w') as fout:\n",
    "#     json.dump(data , fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
